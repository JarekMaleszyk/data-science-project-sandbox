{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1282b669-e2c0-4609-98f8-f0cf396118eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import pyspark\n",
    "except:\n",
    "  !pip install pyspark\n",
    "  import pyspark\n",
    "finally:\n",
    "  from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85522500-356c-403b-9e4b-fcc6cf51f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def create_folder(directory_name: str) -> None:\n",
    "    try:\n",
    "        os.mkdir(Path(directory_name))\n",
    "        print(f\"Directory '{directory_name}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{directory_name}' already exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{directory_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "def remove_file(directory_name: str, file_name: str) -> None:\n",
    "    try:\n",
    "        os.remove(f\"{Path(directory_name)}/{file_name}\") \n",
    "        print(f\"File '{Path(directory_name)}/{file_name}' removed successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"File '{Path(directory_name)}/{file_name}' doesn't exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to remove file '{Path(directory_name)}/{file_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46e87af-6124-4258-b577-7a53a49e188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory './tmp/' already exists.\n",
      "File 'tmp/electro_product_mock.json' removed successfully.\n",
      "100% [................................................................................] 1537 / 1537"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "try:\n",
    "  import wget\n",
    "except:\n",
    "  !pip install wget -q\n",
    "  import wget\n",
    "\n",
    "try:\n",
    "  import shutil\n",
    "except:\n",
    "  !pip install shutil -q\n",
    "  import shutil\n",
    "\n",
    "FILE_PATH = \"./tmp/\"\n",
    "FILE_NAME = \"electro_product_mock.json\"\n",
    "URL = \"https://raw.githubusercontent.com/JarekMaleszyk/data-science-project-sandbox/refs/heads/main/data.json\"\n",
    "\n",
    "if not os.path.isfile(FILE_PATH):\n",
    "    create_folder(FILE_PATH)\n",
    "    remove_file(FILE_PATH, FILE_NAME) \n",
    "    filename = wget.download(URL)\n",
    "    shutil.move(filename, f\"{Path(FILE_PATH)}/{FILE_NAME}\")\n",
    "\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58187776-921c-4c01-a0e1-7ca8564c32b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/12 16:48:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sparkSession = SparkSession.builder.appName('Spark basics').getOrCreate()\n",
    "sparkSession.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# localhost:4040"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1fc077e-f842-4e0e-8145-cd5b043a6eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (StructType, StructField, StringType, IntegerType,\n",
    "                               ArrayType, DoubleType, BooleanType)\n",
    "\n",
    "schema = StructType(fields=[\n",
    "    StructField(\"id\", IntegerType(), True), # True = nullable\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"category\", StringType(), True),\n",
    "    StructField(\"quantity\", IntegerType(), True),\n",
    "    StructField(\"price\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b7fdc6-6a26-4e54-8adb-6c1efebd89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark_df_products = sparkSession.read\\\n",
    "  .schema(schema)\\\n",
    "  .option(\"multiline\", True)\\\n",
    "  .json(f\"{Path(FILE_PATH)}/{FILE_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e640777b-7e30-4fe8-ba87-53a19a8c4dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df_products.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "517655a5-bc9f-45a0-ae54-658bb7cc9120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+---------------+--------+------+\n",
      "| id|                name|       category|quantity| price|\n",
      "+---+--------------------+---------------+--------+------+\n",
      "|  1|           iPhone 12|    Electronics|      10|899.99|\n",
      "|  2|     Nike Air Max 90|       Clothing|      25|119.99|\n",
      "|  3|KitchenAid Stand ...|Home Appliances|       5|299.99|\n",
      "|  4|    The Great Gatsby|          Books|      50| 12.99|\n",
      "|  5|L'Oreal Paris Mas...|         Beauty|     100|  9.99|\n",
      "|  6|            Yoga Mat|         Sports|      30| 29.99|\n",
      "|  7| Samsung 4K Smart TV|    Electronics|       8|799.99|\n",
      "|  8|        Levi's Jeans|       Clothing|      15| 49.99|\n",
      "|  9|Dyson Vacuum Cleaner|Home Appliances|       3|399.99|\n",
      "| 10| Harry Potter Series|          Books|      20| 15.99|\n",
      "+---+--------------------+---------------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pyspark_df_products.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79eee112-9f48-412a-bf7f-2db5ba4329ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utworzenie danych.\n",
    "newDataFramePayload = [\n",
    "           [1, \"Jules\", \"Damji\", \"https://tinyurl.1\", \"1/4/2016\", 4535, [\"twitter\", \"LinkedIn\"], True],\n",
    "           [2, \"Brooke\",\"Wenig\",\"https://tinyurl.2\", \"5/5/2018\", 8908, [\"twitter\", \"LinkedIn\"], True],\n",
    "           [3, \"Denny\", \"Lee\", \"https://tinyurl.3\",\"6/7/2019\",7659, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"], True],\n",
    "           [4, \"Tathagata\", \"Das\",\"https://tinyurl.4\", \"5/12/2018\", 10568, [\"twitter\", \"FB\"], True],\n",
    "           [5, \"Matei\",\"Zaharia\", \"https://tinyurl.5\", \"5/14/2014\", 40578, [\"web\", \"twitter\", \"FB\", \"LinkedIn\"], True],\n",
    "           [6, \"Reynold\", \"Xin\", \"https://tinyurl.6\", \"3/2/2015\", 25568, [\"twitter\", \"LinkedIn\"], False]\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7bff11d-8d15-41ff-9ea8-22504ae0ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, StringType, ArrayType, BooleanType\n",
    "# from pyspark.sql.functions import *\n",
    "\n",
    "# Zdefiniowanie schematu dla danych.\n",
    "newDataFrameSchema = StructType([\n",
    "   StructField(\"Id\", IntegerType(), False),\n",
    "   StructField(\"First\", StringType(), False),\n",
    "   StructField(\"Last\", StringType(), False),\n",
    "   StructField(\"Url\", StringType(), False),\n",
    "   StructField(\"Published\", StringType(), False),\n",
    "   StructField(\"Hits\", IntegerType(), False),\n",
    "   StructField(\"Campaigns\", ArrayType(StringType()), False),\n",
    "   StructField(\"IsActive\", BooleanType(), False)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00648e93-594d-47bf-8944-b353f8d97880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+-------+-----------------+---------+-----+--------------------+--------+\n",
      "| Id|    First|   Last|              Url|Published| Hits|           Campaigns|IsActive|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+--------+\n",
      "|  1|    Jules|  Damji|https://tinyurl.1| 1/4/2016| 4535| [twitter, LinkedIn]|    true|\n",
      "|  2|   Brooke|  Wenig|https://tinyurl.2| 5/5/2018| 8908| [twitter, LinkedIn]|    true|\n",
      "|  3|    Denny|    Lee|https://tinyurl.3| 6/7/2019| 7659|[web, twitter, FB...|    true|\n",
      "|  4|Tathagata|    Das|https://tinyurl.4|5/12/2018|10568|       [twitter, FB]|    true|\n",
      "|  5|    Matei|Zaharia|https://tinyurl.5|5/14/2014|40578|[web, twitter, FB...|    true|\n",
      "|  6|  Reynold|    Xin|https://tinyurl.6| 3/2/2015|25568| [twitter, LinkedIn]|   false|\n",
      "+---+---------+-------+-----------------+---------+-----+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utworzenie egzemplarza DataFrame za pomocą zdefiniowanego wcześniej schematu.\n",
    "blogs_df = sparkSession.createDataFrame(data=newDataFramePayload, schema=newDataFrameSchema)\n",
    "# Wyświetlenie egzemplarza DataFrame. Powinien on odzwierciedlać przedstawioną wcześniej tabelę.\n",
    "blogs_df.show()\n",
    "\n",
    "# Poza jupyter-lab mozna napisać to jako program główny main.py \n",
    "\n",
    "# # Program główny.\n",
    "# if __name__ == \"__main__\":\n",
    "#    # Utworzenie egzemplarza SparkSession.\n",
    "#    spark = (SparkSession\n",
    "#        .builder\n",
    "#        .appName(\"Example-3_6\")\n",
    "#        .getOrCreate())\n",
    "#    # Utworzenie egzemplarza DataFrame za pomocą zdefiniowanego wcześniej schematu.\n",
    "#    blogs_df = spark.createDataFrame(data, schema)\n",
    "#    # Wyświetlenie egzemplarza DataFrame. Powinien on odzwierciedlać przedstawioną wcześniej tabelę.\n",
    "#    blogs_df.show()\n",
    "\n",
    "# Następnie uruchamiać: spark-submit main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4741b6ed-a722-4867-a17c-db68277f50eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = false)\n",
      " |-- First: string (nullable = false)\n",
      " |-- Last: string (nullable = false)\n",
      " |-- Url: string (nullable = false)\n",
      " |-- Published: string (nullable = false)\n",
      " |-- Hits: integer (nullable = false)\n",
      " |-- Campaigns: array (nullable = false)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- IsActive: boolean (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "blogs_df.printSchema()\n",
    "# blogs_df.schema # wersja podstawowa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36260b9-1610-4c81-b34e-d7ed4dc0d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkSession.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21497fb-8e3e-4402-91c3-1ce66b3e33bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a35fd-e7b4-4efc-9665-7c6b337f5941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c28d72-9467-42b8-bc4e-ff1a66c69da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
