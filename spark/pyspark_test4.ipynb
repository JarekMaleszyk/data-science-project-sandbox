{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMab/Ynp4FuJqr2z0wv/xZO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JarekMaleszyk/data-science-project-sandbox/blob/main/pyspark_test4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {
        "id": "Q3Y6iPt54Ev_"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import pyspark\n",
        "except:\n",
        "  !pip install pyspark\n",
        "  import pyspark\n",
        "finally:\n",
        "  from pyspark.sql import SparkSession\n",
        "  spark = SparkSession.builder.appName('pyspark-notebook').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "EpMW-GKfwk_J",
        "outputId": "d29111f8-88ea-4636-c9c2-7fc563b9f7e1"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7afa36e147f0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://0d881cc87ee3:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-notebook</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header', 'true').csv('/content/simple_data2.csv', inferSchema=True, sep=';')"
      ],
      "metadata": {
        "id": "r7Jf6OpzwlNn"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "sdvS4PJMwlQw"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  spark\n",
        "except AttributeError as ae:\n",
        "  print('spark is stopped')\n",
        "else:\n",
        "  spark.stop()\n",
        "finally:\n",
        "  from pyspark.sql import SparkSession\n",
        "  spark = SparkSession.builder.appName('pyspark-notebook').getOrCreate()"
      ],
      "metadata": {
        "id": "-0JfqGejwlTh"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark = spark.read.option('header', 'true').csv('/content/simple_data2.csv', inferSchema=True, sep=';')"
      ],
      "metadata": {
        "id": "Zk5-B7yEwlbQ"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1LWyf8Mwldt",
        "outputId": "a157b8e2-6c3a-445c-b729-a45e958ad249"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+----------+-------+----------+\n",
            "| name|age|experience| salary|department|\n",
            "+-----+---+----------+-------+----------+\n",
            "| Kris| 31|         6| 2230.3|        IT|\n",
            "| Adam| 30|         5|2230.89|        HR|\n",
            "|Sunny| 39|        14|3230.21|        HR|\n",
            "|  Tom| 28|         5|1890.32|        IT|\n",
            "| John| 40|        18| 3400.0|  HelpDesk|\n",
            "| Mark| 36|        12|4730.04|        IT|\n",
            "|  Bob| 35|         7|1930.05|        IT|\n",
            "|Ellen| 34|         7|2230.96|  HelpDesk|\n",
            "|  Jim| 46|        21|6230.99|        IT|\n",
            "| Paul| 39|        11| 2710.5|        IT|\n",
            "|  Tom| 38|        17|4280.45|        IT|\n",
            "+-----+---+----------+-------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resilient distributed dataset (RDD)"
      ],
      "metadata": {
        "id": "eepnd2o_JHEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = spark.sparkContext.parallelize(df_pyspark.collect())"
      ],
      "metadata": {
        "id": "OQhgsjtUAWw-"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXSK9sheAj0j",
        "outputId": "84bd6c3b-ed12-48ae-8c5f-0fc38091f524"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='Kris', age=31, experience=6, salary=2230.3, department='IT'),\n",
              " Row(name='Adam', age=30, experience=5, salary=2230.89, department='HR'),\n",
              " Row(name='Sunny', age=39, experience=14, salary=3230.21, department='HR'),\n",
              " Row(name='Tom', age=28, experience=5, salary=1890.32, department='IT'),\n",
              " Row(name='John', age=40, experience=18, salary=3400.0, department='HelpDesk'),\n",
              " Row(name='Mark', age=36, experience=12, salary=4730.04, department='IT'),\n",
              " Row(name='Bob', age=35, experience=7, salary=1930.05, department='IT'),\n",
              " Row(name='Ellen', age=34, experience=7, salary=2230.96, department='HelpDesk'),\n",
              " Row(name='Jim', age=46, experience=21, salary=6230.99, department='IT'),\n",
              " Row(name='Paul', age=39, experience=11, salary=2710.5, department='IT'),\n",
              " Row(name='Tom', age=38, experience=17, salary=4280.45, department='IT')]"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmanuhgND2i6",
        "outputId": "2a0e7fd8-3de0-4af6-997b-199b99d18481"
      },
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.take(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCmZX8UnEY5m",
        "outputId": "2bc28184-43cc-46b6-8991-2fe0eac26153"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(name='Kris', age=31, experience=6, salary=2230.3, department='IT')]"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rdd.foreach(lambda x: print(x))"
      ],
      "metadata": {
        "id": "OgIy2d5rFHBE"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapped_rdd = rdd.map(lambda x: (x[0].upper(), x[1]))\n",
        "result = mapped_rdd.collect()\n",
        "print(f'RDD with uppercase name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v95-u0HGFKeK",
        "outputId": "868cad53-7771-4539-fec9-5a822669f5a8"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD with uppercase name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filred_rdd = rdd.filter(lambda x: x[1] > 33)\n",
        "result = filred_rdd.collect()\n",
        "print(f'RDD with age > 30: {result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqFn2jqtGPGt",
        "outputId": "39773860-c887-46cb-fd6b-5e1aea80ecf0"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD with age > 30: [Row(name='Sunny', age=39, experience=14, salary=3230.21, department='HR'), Row(name='John', age=40, experience=18, salary=3400.0, department='HelpDesk'), Row(name='Mark', age=36, experience=12, salary=4730.04, department='IT'), Row(name='Bob', age=35, experience=7, salary=1930.05, department='IT'), Row(name='Ellen', age=34, experience=7, salary=2230.96, department='HelpDesk'), Row(name='Jim', age=46, experience=21, salary=6230.99, department='IT'), Row(name='Paul', age=39, experience=11, salary=2710.5, department='IT'), Row(name='Tom', age=38, experience=17, salary=4280.45, department='IT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_rdd = rdd.map(lambda x: (x[0], x[1])).reduceByKey(lambda x, y: x + y)\n",
        "# Map the RDD to ensure each element is a key-value pair (name, age) before applying reduceByKey.\n",
        "result = reduced_rdd.collect()\n",
        "print(f'RDD with age reduced: {result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCoac2u9G328",
        "outputId": "3889fe0f-39a3-468a-de51-5d848c0418a1"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD with age reduced: [('Sunny', 39), ('Tom', 66), ('Mark', 36), ('Ellen', 34), ('Jim', 46), ('Kris', 31), ('Adam', 30), ('John', 40), ('Bob', 35), ('Paul', 39)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_rdd = rdd.sortBy(lambda x: x[1], ascending=False)\n",
        "result = sorted_rdd.collect()\n",
        "print(f'RDD with sorted by age: {result}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w327cV3sHO17",
        "outputId": "ec5232bb-dbd6-4932-f332-de683063721f"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RDD with sorted by age: [Row(name='Jim', age=46, experience=21, salary=6230.99, department='IT'), Row(name='John', age=40, experience=18, salary=3400.0, department='HelpDesk'), Row(name='Sunny', age=39, experience=14, salary=3230.21, department='HR'), Row(name='Paul', age=39, experience=11, salary=2710.5, department='IT'), Row(name='Tom', age=38, experience=17, salary=4280.45, department='IT'), Row(name='Mark', age=36, experience=12, salary=4730.04, department='IT'), Row(name='Bob', age=35, experience=7, salary=1930.05, department='IT'), Row(name='Ellen', age=34, experience=7, salary=2230.96, department='HelpDesk'), Row(name='Kris', age=31, experience=6, salary=2230.3, department='IT'), Row(name='Adam', age=30, experience=5, salary=2230.89, department='HR'), Row(name='Tom', age=28, experience=5, salary=1890.32, department='IT')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  rdd.saveAsTextFile('output.txt')\n",
        "except Exception as e:\n",
        "  print(\"folder is not empty\")\n",
        "  !rm -Rf output.txt\n",
        "  rdd.saveAsTextFile('output.txt')\n",
        "finally:\n",
        "  pass\n"
      ],
      "metadata": {
        "id": "JCZKIPQrH4NR"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_text = spark.sparkContext.textFile('output.txt')"
      ],
      "metadata": {
        "id": "lG1ZOFRLIBve"
      },
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "head -5 /content/simple_data2.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbhDP9AyIBVR",
        "outputId": "47cfe071-082d-43e6-9977-e3c5d3030d48"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name;age;experience;salary;department\r\n",
            "Kris;31;6;2230.30;IT\r\n",
            "Adam;30;5;2230.89;HR\r\n",
            "Sunny;39;14;3230.21;HR\r\n",
            "Tom;28;5;1890.32;IT\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -5 /content/simple_data2.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI9u1DyLIBXm",
        "outputId": "1b2a5d96-a36f-4408-c18f-8bf49333d50d"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name;age;experience;salary;department\r\n",
            "Kris;31;6;2230.30;IT\r\n",
            "Adam;30;5;2230.89;HR\r\n",
            "Sunny;39;14;3230.21;HR\r\n",
            "Tom;28;5;1890.32;IT\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pyspark.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEDxETDFIBac",
        "outputId": "3a2aca09-aa7d-488f-d534-d9d98a794e3e"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: string (nullable = true)\n",
            " |-- age: integer (nullable = true)\n",
            " |-- experience: integer (nullable = true)\n",
            " |-- salary: double (nullable = true)\n",
            " |-- department: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read single line JSON\n",
        "# Each row is a JSON record, records are separated by new line\n",
        "json_file_path = \"/content/data.json\"\n",
        "df_json = spark.read.option(\"multiline\",\"true\").json(json_file_path) #In Spark 2.2+ you can read json file of multiline using following command.\n",
        "# or df_json = spark.read.json(json_file_path, multiline=True)"
      ],
      "metadata": {
        "id": "9WBRABAgIAwe"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_json.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiI-NW0sMV3S",
        "outputId": "7767164a-49c0-4459-b7d5-95705e9dc26a"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- category: string (nullable = true)\n",
            " |-- id: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- quantity: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dr.write.parquet(path)\n",
        "# dr.read.parquet(path)"
      ],
      "metadata": {
        "id": "JljXI3CpTFIC"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "XVAWsEU3fXSN"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C2hW_MkYfY4K"
      },
      "execution_count": 298,
      "outputs": []
    }
  ]
}